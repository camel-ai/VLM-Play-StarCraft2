from openai import OpenAI
import os
from vlm_attention.config.config import get_config
## Set the API key and model name

"""
simple test the openai api
"""
MODEL="gpt-4o-mini"
proxy_url = get_config("proxy", "url")

os.environ["http_proxy"] = proxy_url
os.environ["https_proxy"] = proxy_url
client = OpenAI(api_key=get_config("openai", "api_key"))
completion = client.chat.completions.create(
  model=MODEL,
  messages=[
    {"role": "system", "content": "You are a helpful assistant. Help me with my math homework!"}, # <-- This is the system message that provides context to the model
    {"role": "user", "content": "Hello! Could you solve 2+2?"}  # <-- This is the user message for which the model will generate a response
  ]
)

print("Assistant: " + completion.choices[0].message.content) # <-- This is the response generated by the model